{"cells":[{"cell_type":"markdown","metadata":{"id":"VTze-VbeU1c0"},"source":["# Fine-tune a DialoGPT model\n","\n","Adapted from the notebook in [this Medium post](https://towardsdatascience.com/make-your-own-rick-sanchez-bot-with-transformers-and-dialogpt-fine-tuning-f85e6d1f4e30?gi=e4a72d1510f0)."]},{"cell_type":"markdown","metadata":{"id":"Y17kuzFNUSrZ"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4117,"status":"ok","timestamp":1667574515573,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"GBfltjGHT6KG","outputId":"bfe40eaa-d371-4172-cc90-e1c466474ecd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1033,"status":"ok","timestamp":1667574516589,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"T8fgmjaqUErq","outputId":"f6fe2efd-3ffc-4ac6-a77a-83850afe3dd8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 5, in \u003cmodule\u003e\n","    from pip._internal.cli.main import main\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 9, in \u003cmodule\u003e\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in \u003cmodule\u003e\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main_parser.py\", line 8, in \u003cmodule\u003e\n","    from pip._internal.cli import cmdoptions\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/cmdoptions.py\", line 23, in \u003cmodule\u003e\n","    from pip._internal.cli.parser import ConfigOptionParser\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/parser.py\", line 12, in \u003cmodule\u003e\n","    from pip._internal.configuration import Configuration, ConfigurationError\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/configuration.py\", line 21, in \u003cmodule\u003e\n","    from pip._internal.exceptions import (\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/exceptions.py\", line 7, in \u003cmodule\u003e\n","    from pip._vendor.pkg_resources import Distribution\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3251, in \u003cmodule\u003e\n","    @_call_aside\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3235, in _call_aside\n","    f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3264, in _initialize_master_working_set\n","    working_set = WorkingSet._build_master()\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 574, in _build_master\n","    ws = cls()\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 567, in __init__\n","    self.add_entry(entry)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 623, in add_entry\n","    for dist in find_distributions(entry, True):\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2065, in find_on_path\n","    for dist in factory(fullpath):\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2127, in distributions_from_metadata\n","    if len(os.listdir(path)) == 0:\n","KeyboardInterrupt\n"]}],"source":["!pip -q install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtCreyG8UG1s"},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnv5kT-mLsB-"},"outputs":[],"source":["# all the imports\n","\n","import glob\n","import logging\n","import os\n","import pickle\n","import random\n","import re\n","import shutil\n","from typing import Dict, List, Tuple\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm.notebook import tqdm, trange\n","\n","from pathlib import Path\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","\n","try:\n","    from torch.utils.tensorboard import SummaryWriter\n","except ImportError:\n","    from tensorboardX import SummaryWriter"]},{"cell_type":"markdown","metadata":{"id":"BmrbGB8aUmBm"},"source":["## Get Data from Kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":766,"status":"ok","timestamp":1667574517339,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"ftBYBoOoV_Er","outputId":"20654a41-b61e-4a84-9a17-9c7938735ce7"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"]}],"source":["!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1950,"status":"ok","timestamp":1667574519273,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"fbITTMcLVbI_","outputId":"69d736f6-237e-4fd9-ae66-b1b592f0943e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Harry%20Potter%201.csv: Skipping, found more recently modified local copy (use --force to force download)\n"]}],"source":["!kaggle datasets download gulsahdemiryurek/harry-potter-dataset -f \"Harry Potter 1.csv\"  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RXdJTSVwWGHj"},"outputs":[],"source":["data = pd.read_csv(\"Harry%20Potter%201.csv\", sep=';')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ytILjX1KrD1Y"},"outputs":[],"source":["data.rename(columns={'Character':'name', 'Sentence':'line'},inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1667574519273,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"h6kGx-9eG7qA","outputId":"1958fb51-7312-4428-b807-ad25254d7880"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-83e4ce13-d7d5-4875-aecd-2b5036d03e0f\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ename\u003c/th\u003e\n","      \u003cth\u003eline\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e570\u003c/th\u003e\n","      \u003ctd\u003eHarry\u003c/td\u003e\n","      \u003ctd\u003eWe got lost.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1372\u003c/th\u003e\n","      \u003ctd\u003eHermione\u003c/td\u003e\n","      \u003ctd\u003eUh! I remember reading something in Herbology.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1425\u003c/th\u003e\n","      \u003ctd\u003eRon\u003c/td\u003e\n","      \u003ctd\u003ePawn to C-3!\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e382\u003c/th\u003e\n","      \u003ctd\u003eGinny\u003c/td\u003e\n","      \u003ctd\u003eGood luck.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e99\u003c/th\u003e\n","      \u003ctd\u003ePetunia\u003c/td\u003e\n","      \u003ctd\u003eYou're going to go to the state school.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1535\u003c/th\u003e\n","      \u003ctd\u003eDumbledore\u003c/td\u003e\n","      \u003ctd\u003eAh, I'm afraid there are ways in which he can ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83e4ce13-d7d5-4875-aecd-2b5036d03e0f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-83e4ce13-d7d5-4875-aecd-2b5036d03e0f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-83e4ce13-d7d5-4875-aecd-2b5036d03e0f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["             name                                               line\n","570         Harry                                       We got lost.\n","1372   Hermione      Uh! I remember reading something in Herbology. \n","1425        Ron                                         Pawn to C-3!\n","382         Ginny                                         Good luck.\n","99        Petunia            You're going to go to the state school.\n","1535  Dumbledore   Ah, I'm afraid there are ways in which he can ..."]},"execution_count":187,"metadata":{},"output_type":"execute_result"}],"source":["data.sample(6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PG8v6--qWUwj"},"outputs":[],"source":["CHARACTER_NAME = 'Harry'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZUcEMd2WLDT"},"outputs":[],"source":["contexted = []\n","\n","# context window of size 7\n","n = 7\n","\n","for i in data[data.name == CHARACTER_NAME].index:\n","  if i \u003c n:\n","    continue\n","  row = []\n","  prev = i - 1 - n # we additionally substract 1, so row will contain current responce and 7 previous responces  \n","  for j in range(i, prev, -1):\n","    row.append(data.line[j])\n","    contexted.append(row)\n","\n","columns = ['response', 'context'] \n","columns = columns + ['context/' + str(i) for i in range(n - 1)]\n","\n","df = pd.DataFrame.from_records(contexted, columns=columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":736},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1667574519273,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"4T5OlNZHUxij","outputId":"7748b2f9-4728-45df-fa00-acf1763f457f"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-a06e5e9d-5fc5-49a1-b4fd-360fe6b6ff3d\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eresponse\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext/0\u003c/th\u003e\n","      \u003cth\u003econtext/1\u003c/th\u003e\n","      \u003cth\u003econtext/2\u003c/th\u003e\n","      \u003cth\u003econtext/3\u003c/th\u003e\n","      \u003cth\u003econtext/4\u003c/th\u003e\n","      \u003cth\u003econtext/5\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e167\u003c/th\u003e\n","      \u003ctd\u003eThat's Dudley's old uniform.\u003c/td\u003e\n","      \u003ctd\u003eThis is what you'll going to be wearing, when ...\u003c/td\u003e\n","      \u003ctd\u003eWhere you belong.\u003c/td\u003e\n","      \u003ctd\u003eYou're going to go to the state school.\u003c/td\u003e\n","      \u003ctd\u003eDon't be so stupid!\u003c/td\u003e\n","      \u003ctd\u003eWhat? You? Go to Smeltings?\u003c/td\u003e\n","      \u003ctd\u003eWill I have to wear that too?\u003c/td\u003e\n","      \u003ctd\u003eProudest moment of my life.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1077\u003c/th\u003e\n","      \u003ctd\u003eNo.\u003c/td\u003e\n","      \u003ctd\u003eWanna go and visit Hagrid?\u003c/td\u003e\n","      \u003ctd\u003eNo.\u003c/td\u003e\n","      \u003ctd\u003eWanna play chess?\u003c/td\u003e\n","      \u003ctd\u003eI'll be right back.\u003c/td\u003e\n","      \u003ctd\u003eRon?\u003c/td\u003e\n","      \u003ctd\u003eDo you like yours, Ron?\u003c/td\u003e\n","      \u003ctd\u003eBoth my parents are dead.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e437\u003c/th\u003e\n","      \u003ctd\u003eBut why am I famous, Hagrid?\u003c/td\u003e\n","      \u003ctd\u003eSee, Harry? You're famous.\u003c/td\u003e\n","      \u003ctd\u003eGoodbye.\u003c/td\u003e\n","      \u003ctd\u003eLots to buy.\u003c/td\u003e\n","      \u003ctd\u003eYes, well, must be going now.\u003c/td\u003e\n","      \u003ctd\u003eNot that you need it, eh, Potter?\u003c/td\u003e\n","      \u003ctd\u003eFearfully fascinating subject.\u003c/td\u003e\n","      \u003ctd\u003eOh, nice to meet you.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e295\u003c/th\u003e\n","      \u003ctd\u003eI mean, I'm just Harry.\u003c/td\u003e\n","      \u003ctd\u003eI mean...l can't be a wizard.\u003c/td\u003e\n","      \u003ctd\u003eNo, you've made a mistake.\u003c/td\u003e\n","      \u003ctd\u003eAnd a thumping good one, I'd wager, once you'r...\u003c/td\u003e\n","      \u003ctd\u003eA wizard.\u003c/td\u003e\n","      \u003ctd\u003eI'm a what?\u003c/td\u003e\n","      \u003ctd\u003eYou're a wizard, Harry.\u003c/td\u003e\n","      \u003ctd\u003eLearnt what?\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1188\u003c/th\u003e\n","      \u003ctd\u003eAll right there, Ron?\u003c/td\u003e\n","      \u003ctd\u003eMm. Alas. Earwax.\u003c/td\u003e\n","      \u003ctd\u003eBut I think I could be safe with a nice toffee...\u003c/td\u003e\n","      \u003ctd\u003eI was most unfortunate in my youth to come acr...\u003c/td\u003e\n","      \u003ctd\u003eAh. Bertie Bott's Every Flavour Beans.\u003c/td\u003e\n","      \u003ctd\u003eLove, Harry, love.\u003c/td\u003e\n","      \u003ctd\u003eWhat is it?\u003c/td\u003e\n","      \u003ctd\u003eIt lives in your very skin.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e90\u003c/th\u003e\n","      \u003ctd\u003eWas it nice there?\u003c/td\u003e\n","      \u003ctd\u003eYou're from Burma, aren't you?\u003c/td\u003e\n","      \u003ctd\u003eI mean, do you talk to people often?\u003c/td\u003e\n","      \u003ctd\u003eDo you...?\u003c/td\u003e\n","      \u003ctd\u003eIt's just, I've never talked to a snake before.\u003c/td\u003e\n","      \u003ctd\u003eCan you hear me?\u003c/td\u003e\n","      \u003ctd\u003e...watching people press their ugly faces in o...\u003c/td\u003e\n","      \u003ctd\u003eHe doesn't understand what it's like, lying th...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a06e5e9d-5fc5-49a1-b4fd-360fe6b6ff3d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-a06e5e9d-5fc5-49a1-b4fd-360fe6b6ff3d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a06e5e9d-5fc5-49a1-b4fd-360fe6b6ff3d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                          response  \\\n","167   That's Dudley's old uniform.   \n","1077                           No.   \n","437   But why am I famous, Hagrid?   \n","295        I mean, I'm just Harry.   \n","1188         All right there, Ron?   \n","90              Was it nice there?   \n","\n","                                                context  \\\n","167   This is what you'll going to be wearing, when ...   \n","1077                         Wanna go and visit Hagrid?   \n","437                          See, Harry? You're famous.   \n","295                       I mean...l can't be a wizard.   \n","1188                                  Mm. Alas. Earwax.   \n","90                       You're from Burma, aren't you?   \n","\n","                                              context/0  \\\n","167                                   Where you belong.   \n","1077                                                No.   \n","437                                            Goodbye.   \n","295                          No, you've made a mistake.   \n","1188  But I think I could be safe with a nice toffee...   \n","90                 I mean, do you talk to people often?   \n","\n","                                              context/1  \\\n","167             You're going to go to the state school.   \n","1077                                  Wanna play chess?   \n","437                                        Lots to buy.   \n","295   And a thumping good one, I'd wager, once you'r...   \n","1188  I was most unfortunate in my youth to come acr...   \n","90                                           Do you...?   \n","\n","                                            context/2  \\\n","167                               Don't be so stupid!   \n","1077                              I'll be right back.   \n","437                     Yes, well, must be going now.   \n","295                                         A wizard.   \n","1188          Ah. Bertie Bott's Every Flavour Beans.    \n","90    It's just, I've never talked to a snake before.   \n","\n","                              context/3  \\\n","167         What? You? Go to Smeltings?   \n","1077                               Ron?   \n","437   Not that you need it, eh, Potter?   \n","295                         I'm a what?   \n","1188                Love, Harry, love.    \n","90                     Can you hear me?   \n","\n","                                              context/4  \\\n","167                       Will I have to wear that too?   \n","1077                            Do you like yours, Ron?   \n","437                      Fearfully fascinating subject.   \n","295                             You're a wizard, Harry.   \n","1188                                        What is it?   \n","90    ...watching people press their ugly faces in o...   \n","\n","                                              context/5  \n","167                         Proudest moment of my life.  \n","1077                          Both my parents are dead.  \n","437                               Oh, nice to meet you.  \n","295                                        Learnt what?  \n","1188                        It lives in your very skin.  \n","90    He doesn't understand what it's like, lying th...  "]},"execution_count":190,"metadata":{},"output_type":"execute_result"}],"source":["df.sample(6)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1667574519273,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"NGy0MxMQVIAP","outputId":"900e3503-ced2-4aa7-d775-79c6d2ff0d49"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-39de96ae-8cd4-49be-a0d6-269c59f34d4e\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eresponse\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext/0\u003c/th\u003e\n","      \u003cth\u003econtext/1\u003c/th\u003e\n","      \u003cth\u003econtext/2\u003c/th\u003e\n","      \u003cth\u003econtext/3\u003c/th\u003e\n","      \u003cth\u003econtext/4\u003c/th\u003e\n","      \u003cth\u003econtext/5\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e959\u003c/th\u003e\n","      \u003ctd\u003eWhere's Hermione?\u003c/td\u003e\n","      \u003ctd\u003eI think she heard you.\u003c/td\u003e\n","      \u003ctd\u003eNo wonder she hasn't got any friends!\u003c/td\u003e\n","      \u003ctd\u003eHonestly, she's a nightmare.\u003c/td\u003e\n","      \u003ctd\u003eIt's Leviosa, not Leviosar.\u003c/td\u003e\n","      \u003ctd\u003eI think we're going to need another feather ov...\u003c/td\u003e\n","      \u003ctd\u003eWhooaaa! Ooh.\u003c/td\u003e\n","      \u003ctd\u003eWingard Levosa. Wingardly Lev...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e335\u003c/th\u003e\n","      \u003ctd\u003eYou knew all along and you never told me?\u003c/td\u003e\n","      \u003ctd\u003eYou knew?\u003c/td\u003e\n","      \u003ctd\u003eWe swore when we took him in we'd put a stop t...\u003c/td\u003e\n","      \u003ctd\u003eHe will not be going there!\u003c/td\u003e\n","      \u003ctd\u003eWe are pleased to inform you that you have bee...\u003c/td\u003e\n","      \u003ctd\u003eDear Mr. Potter,\u003c/td\u003e\n","      \u003ctd\u003eAnything you couldn't explain, when you were a...\u003c/td\u003e\n","      \u003ctd\u003eWell, Just Harry, did you ever make anything h...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e308\u003c/th\u003e\n","      \u003ctd\u003eDear Mr. Potter,\u003c/td\u003e\n","      \u003ctd\u003eAnything you couldn't explain, when you were a...\u003c/td\u003e\n","      \u003ctd\u003eWell, Just Harry, did you ever make anything h...\u003c/td\u003e\n","      \u003ctd\u003eJust Harry.\u003c/td\u003e\n","      \u003ctd\u003eI mean, I'm just Harry.\u003c/td\u003e\n","      \u003ctd\u003eI mean...l can't be a wizard.\u003c/td\u003e\n","      \u003ctd\u003eNo, you've made a mistake.\u003c/td\u003e\n","      \u003ctd\u003eAnd a thumping good one, I'd wager, once you'r...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e380\u003c/th\u003e\n","      \u003ctd\u003eOne pair of dragon hide gloves.\u003c/td\u003e\n","      \u003ctd\u003eEssential bit of equipment, Harry.\u003c/td\u003e\n","      \u003ctd\u003eFirst year's students will require three sets ...\u003c/td\u003e\n","      \u003ctd\u003eUnless you'd rather stay, of course.\u003c/td\u003e\n","      \u003ctd\u003eBest be off.\u003c/td\u003e\n","      \u003ctd\u003eOoh, We're a bit behind schedule.\u003c/td\u003e\n","      \u003ctd\u003eOkay.\u003c/td\u003e\n","      \u003ctd\u003eStrickly speaking, I'm not allowed to do magic.\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1163\u003c/th\u003e\n","      \u003ctd\u003eI don't know.\u003c/td\u003e\n","      \u003ctd\u003eWhat is that?\u003c/td\u003e\n","      \u003ctd\u003eLucky Hermione pays attention in Herbology.\u003c/td\u003e\n","      \u003ctd\u003eWhew. Lucky we didn't panic!\u003c/td\u003e\n","      \u003ctd\u003eOkay.\u003c/td\u003e\n","      \u003ctd\u003eYeah.\u003c/td\u003e\n","      \u003ctd\u003eRon, are you okay?\u003c/td\u003e\n","      \u003ctd\u003eAhhh!\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39de96ae-8cd4-49be-a0d6-269c59f34d4e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-39de96ae-8cd4-49be-a0d6-269c59f34d4e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-39de96ae-8cd4-49be-a0d6-269c59f34d4e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                                       response  \\\n","959                           Where's Hermione?   \n","335   You knew all along and you never told me?   \n","308                            Dear Mr. Potter,   \n","380             One pair of dragon hide gloves.   \n","1163                             I don't know.    \n","\n","                                                context  \\\n","959                              I think she heard you.   \n","335                                          You knew?    \n","308   Anything you couldn't explain, when you were a...   \n","380                  Essential bit of equipment, Harry.   \n","1163                                      What is that?   \n","\n","                                              context/0  \\\n","959               No wonder she hasn't got any friends!   \n","335   We swore when we took him in we'd put a stop t...   \n","308   Well, Just Harry, did you ever make anything h...   \n","380   First year's students will require three sets ...   \n","1163        Lucky Hermione pays attention in Herbology.   \n","\n","                                 context/1  \\\n","959          Honestly, she's a nightmare.    \n","335            He will not be going there!   \n","308                            Just Harry.   \n","380   Unless you'd rather stay, of course.   \n","1163          Whew. Lucky we didn't panic!   \n","\n","                                              context/2  \\\n","959                        It's Leviosa, not Leviosar.    \n","335   We are pleased to inform you that you have bee...   \n","308                             I mean, I'm just Harry.   \n","380                                        Best be off.   \n","1163                                              Okay.   \n","\n","                                              context/3  \\\n","959   I think we're going to need another feather ov...   \n","335                                    Dear Mr. Potter,   \n","308                       I mean...l can't be a wizard.   \n","380                   Ooh, We're a bit behind schedule.   \n","1163                                              Yeah.   \n","\n","                                              context/4  \\\n","959                                       Whooaaa! Ooh.   \n","335   Anything you couldn't explain, when you were a...   \n","308                          No, you've made a mistake.   \n","380                                               Okay.   \n","1163                                 Ron, are you okay?   \n","\n","                                              context/5  \n","959                   Wingard Levosa. Wingardly Lev...   \n","335   Well, Just Harry, did you ever make anything h...  \n","308   And a thumping good one, I'd wager, once you'r...  \n","380     Strickly speaking, I'm not allowed to do magic.  \n","1163                                              Ahhh!  "]},"execution_count":191,"metadata":{},"output_type":"execute_result"}],"source":["trn_df, val_df = train_test_split(df, test_size=0.1)\n","trn_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aEeJQlAKWtiJ"},"outputs":[],"source":["# create dataset suitable for our model\n","def construct_conv(row, tokenizer, eos = True):\n","    flatten = lambda l: [item for sublist in l for item in sublist]\n","    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n","    conv = flatten(conv)\n","    return conv\n","\n","class ConversationDataset(Dataset):\n","    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n","\n","        block_size = block_size - (tokenizer.model_max_length - tokenizer.max_len_single_sentence)\n","\n","        directory = args.cache_dir\n","        cached_features_file = os.path.join(\n","            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n","        )\n","\n","        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n","            logger.info(\"Loading features from cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"rb\") as handle:\n","                self.examples = pickle.load(handle)\n","        else:\n","            logger.info(\"Creating features from dataset file at %s\", directory)\n","\n","            self.examples = []\n","            for _, row in df.iterrows():\n","                conv = construct_conv(row, tokenizer)\n","                self.examples.append(conv)\n","\n","            logger.info(\"Saving features into cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"wb\") as handle:\n","                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, item):\n","        return torch.tensor(self.examples[item], dtype=torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3iHwoKlWyrs"},"outputs":[],"source":["# Cacheing and storing of data/checkpoints\n","\n","def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n","    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n","\n","\n","def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu \u003e 0:\n","        torch.cuda.manual_seed_all(args.seed)\n","\n","\n","def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -\u003e List[str]:\n","    ordering_and_checkpoint_path = []\n","\n","    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n","\n","    for path in glob_checkpoints:\n","        if use_mtime:\n","            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n","        else:\n","            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n","            if regex_match and regex_match.groups():\n","                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n","\n","    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n","    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n","    return checkpoints_sorted\n","\n","\n","def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -\u003e None:\n","    if not args.save_total_limit:\n","        return\n","    if args.save_total_limit \u003c= 0:\n","        return\n","\n","    # Check if we should delete older checkpoint(s)\n","    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n","    if len(checkpoints_sorted) \u003c= args.save_total_limit:\n","        return\n","\n","    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n","    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n","    for checkpoint in checkpoints_to_be_deleted:\n","        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n","        shutil.rmtree(checkpoint)"]},{"cell_type":"markdown","metadata":{"id":"EEDdTJTqUwZJ"},"source":["## Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"elapsed":1050,"status":"error","timestamp":1667574520306,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"r2cE0fY5UHpz","outputId":"2d731059-7bc1-4004-b3ba-1158397f9bc4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:1136: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-194-a28d7e46eed2\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"microsoft/DialoGPT-medium\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"microsoft/DialoGPT-medium\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[0;32m-\u003e 1138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 439\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             )\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 776\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 559\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                     \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 626\u001b[0;31m                     \u001b[0m_commit_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m                 )\n\u001b[1;32m    628\u001b[0m                 \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_commit_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 420\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                     \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1057\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 )\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, use_auth_token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1357\u001b[0;31m         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m     )\n\u001b[1;32m   1359\u001b[0m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 406\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         )\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 442\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 105\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 344\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_fingerprint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mca_certs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 319\u001b[0;31m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_verify_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mca_certs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Python 2.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from transformers import AutoModelWithLMHead, AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n","model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-medium\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ra2vsRp-UMXo"},"outputs":[],"source":["\"\"\"\n","Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n","GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n","using a masked language modeling (MLM) loss.\n","\"\"\"\n","\n","# Configs\n","logger = logging.getLogger(__name__)\n","\n","MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n","MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2OnASqJjUNJa"},"outputs":[],"source":["# Args to allow for easy convertion of python script to notebook\n","class Args():\n","    def __init__(self):\n","        self.output_dir = 'output-medium'\n","        self.model_type = 'gpt2'\n","        self.model_name_or_path = 'microsoft/DialoGPT-medium'\n","        self.config_name = 'microsoft/DialoGPT-medium'\n","        self.tokenizer_name = 'microsoft/DialoGPT-medium'\n","        self.cache_dir = 'cached'\n","        self.block_size = 512\n","        self.do_train = True\n","        self.do_eval = True\n","        self.evaluate_during_training = False\n","        self.per_gpu_train_batch_size = 4\n","        self.per_gpu_eval_batch_size = 4\n","        self.gradient_accumulation_steps = 1\n","        self.learning_rate = 5e-5\n","        self.weight_decay = 0.0\n","        self.adam_epsilon = 1e-8\n","        self.max_grad_norm = 1.0\n","        #number of iteration for training\n","        self.num_train_epochs = 7\n","        self.max_steps = -1\n","        self.warmup_steps = 0\n","        self.logging_steps = 1000\n","        self.save_steps = 3500\n","        self.save_total_limit = None\n","        self.eval_all_checkpoints = False\n","        self.no_cuda = False\n","        self.overwrite_output_dir = True\n","        self.overwrite_cache = True\n","        self.should_continue = False\n","        self.seed = 42\n","        self.local_rank = -1\n","        self.fp16 = False\n","        self.fp16_opt_level = 'O1'\n","\n","args = Args()"]},{"cell_type":"markdown","metadata":{"id":"9Q1dTFXxW9NE"},"source":["## Train and Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PaarIDZrW81h"},"outputs":[],"source":["def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -\u003e Tuple[int, float]:\n","    \"\"\" Train the model \"\"\"\n","    if args.local_rank in [-1, 0]:\n","        tb_writer = SummaryWriter()\n","\n","    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n","    train_dataloader = DataLoader(\n","        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    if args.max_steps \u003e 0:\n","        t_total = args.max_steps\n","        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n","    else:\n","        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n","    model.resize_token_embeddings(len(tokenizer))\n","    # add_special_tokens_(model, tokenizer)\n","\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": args.weight_decay,\n","        },\n","        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","    )\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if (\n","        args.model_name_or_path\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n","    ):\n","        # Load in optimizer and scheduler states\n","        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n","\n","    if args.fp16:\n","        try:\n","            from apex import amp\n","        except ImportError:\n","            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n","\n","    # multi-gpu training (should be after apex fp16 initialization)\n","    if args.n_gpu \u003e 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Distributed training (should be after apex fp16 initialization)\n","    if args.local_rank != -1:\n","        model = torch.nn.parallel.DistributedDataParallel(\n","            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n","        )\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_dataset))\n","    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n","    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n","    logger.info(\n","        \"  Total train batch size (w. parallel, distributed \u0026 accumulation) = %d\",\n","        args.train_batch_size\n","        * args.gradient_accumulation_steps\n","        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n","    )\n","    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    epochs_trained = 0\n","    steps_trained_in_current_epoch = 0\n","    # Check if continuing training from a checkpoint\n","    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n","        try:\n","            # set global_step to gobal_step of last saved checkpoint from model path\n","            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n","            global_step = int(checkpoint_suffix)\n","            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n","            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n","\n","            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n","            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n","            logger.info(\"  Continuing training from global step %d\", global_step)\n","            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n","        except ValueError:\n","            logger.info(\"  Starting fine-tuning.\")\n","\n","    tr_loss, logging_loss = 0.0, 0.0\n","\n","    model.zero_grad()\n","    train_iterator = trange(\n","        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n","    )\n","    set_seed(args)  # Added here for reproducibility\n","    for _ in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n","        for step, batch in enumerate(epoch_iterator):\n","\n","            # Skip past any already trained steps if resuming training\n","            if steps_trained_in_current_epoch \u003e 0:\n","                steps_trained_in_current_epoch -= 1\n","                continue\n","\n","            inputs, labels = (batch, batch)\n","            if inputs.shape[1] \u003e 1024: continue\n","            inputs = inputs.to(args.device)\n","            labels = labels.to(args.device)\n","            model.train()\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n","\n","            if args.n_gpu \u003e 1:\n","                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n","            if args.gradient_accumulation_steps \u003e 1:\n","                loss = loss / args.gradient_accumulation_steps\n","\n","            if args.fp16:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            tr_loss += loss.item()\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\n","                if args.fp16:\n","                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n","                else:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if args.local_rank in [-1, 0] and args.logging_steps \u003e 0 and global_step % args.logging_steps == 0:\n","                    # Log metrics\n","                    if (\n","                        args.local_rank == -1 and args.evaluate_during_training\n","                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n","                        results = evaluate(args, model, tokenizer)\n","                        for key, value in results.items():\n","                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n","                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n","                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n","                    logging_loss = tr_loss\n","\n","                if args.local_rank in [-1, 0] and args.save_steps \u003e 0 and global_step % args.save_steps == 0:\n","                    checkpoint_prefix = \"checkpoint\"\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n","                    os.makedirs(output_dir, exist_ok=True)\n","                    model_to_save = (\n","                        model.module if hasattr(model, \"module\") else model\n","                    )  # Take care of distributed/parallel training\n","                    model_to_save.save_pretrained(output_dir)\n","                    tokenizer.save_pretrained(output_dir)\n","\n","                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n","                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n","\n","                    _rotate_checkpoints(args, checkpoint_prefix)\n","\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n","\n","            if args.max_steps \u003e 0 and global_step \u003e args.max_steps:\n","                epoch_iterator.close()\n","                break\n","        if args.max_steps \u003e 0 and global_step \u003e args.max_steps:\n","            train_iterator.close()\n","            break\n","\n","    if args.local_rank in [-1, 0]:\n","        tb_writer.close()\n","\n","    return global_step, tr_loss / global_step\n","\n","# Evaluation of some model\n","\n","def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -\u003e Dict:\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args.output_dir\n","\n","    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n","    os.makedirs(eval_output_dir, exist_ok=True)\n","    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n","    # Note that DistributedSampler samples randomly\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(\n","        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    # multi-gpu evaluate\n","    if args.n_gpu \u003e 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        inputs, labels = (batch, batch)\n","        inputs = inputs.to(args.device)\n","        labels = labels.to(args.device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs, labels=labels)\n","            lm_loss = outputs[0]\n","            eval_loss += lm_loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    perplexity = torch.exp(torch.tensor(eval_loss))\n","\n","    result = {\"perplexity\": perplexity}\n","\n","    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCnGAJWbXD9C"},"outputs":[],"source":["# Main runner\n","\n","def main(df_trn, df_val):\n","    args = Args()\n","    \n","    if args.should_continue:\n","        sorted_checkpoints = _sorted_checkpoints(args)\n","        if len(sorted_checkpoints) == 0:\n","            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n","        else:\n","            args.model_name_or_path = sorted_checkpoints[-1]\n","\n","    if (\n","        os.path.exists(args.output_dir)\n","        and os.listdir(args.output_dir)\n","        and args.do_train\n","        and not args.overwrite_output_dir\n","        and not args.should_continue\n","    ):\n","        raise ValueError(\n","            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n","                args.output_dir\n","            )\n","        )\n","\n","    # Setup CUDA, GPU \u0026 distributed training\n","    device = torch.device(\"cuda\")\n","    args.n_gpu = torch.cuda.device_count()\n","    args.device = device\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    logger.warning(\n","        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n","        args.local_rank,\n","        device,\n","        args.n_gpu,\n","        bool(args.local_rank != -1),\n","        args.fp16,\n","    )\n","\n","    # Set seed\n","    set_seed(args)\n","\n","    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n","    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n","    model = AutoModelWithLMHead.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=False,\n","        config=config,\n","        cache_dir=args.cache_dir,\n","    )\n","    model.to(args.device)\n","    \n","    logger.info(\"Training/evaluation parameters %s\", args)\n","\n","    # Training\n","    if args.do_train:\n","        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n","\n","        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n","    if args.do_train:\n","        # Create output directory if needed\n","        os.makedirs(args.output_dir, exist_ok=True)\n","\n","        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","        # They can then be reloaded using `from_pretrained()`\n","        model_to_save = (\n","            model.module if hasattr(model, \"module\") else model\n","        )  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(args.output_dir)\n","        tokenizer.save_pretrained(args.output_dir)\n","\n","        # Good practice: save your training arguments together with the trained model\n","        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n","\n","        # Load a trained model and vocabulary that you have fine-tuned\n","        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n","        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n","        model.to(args.device)\n","\n","    # Evaluation\n","    results = {}\n","    if args.do_eval and args.local_rank in [-1, 0]:\n","        checkpoints = [args.output_dir]\n","        if args.eval_all_checkpoints:\n","            checkpoints = list(\n","                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n","            )\n","            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) \u003e 1 else \"\"\n","            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n","\n","            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"7NWvkdR-XHeB"},"source":["## Run the Main Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e61zo2JtXGNX"},"outputs":[],"source":["main(trn_df, val_df)"]},{"cell_type":"markdown","metadata":{"id":"YRpQ_n2zXQj-"},"source":["## Load the Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGw3qgfaXQHX"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-medium')\n","model = AutoModelWithLMHead.from_pretrained('output-medium')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAWsiAvNXbxd"},"outputs":[],"source":["# Let's chat for 4 lines\n","for step in range(4):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    new_user_input_ids = tokenizer.encode(input(\"\u003e\u003e User:\") + tokenizer.eos_token, return_tensors='pt')\n","    # print(new_user_input_ids)\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step \u003e 0 else new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(\n","        bot_input_ids, max_length=200,\n","        pad_token_id=tokenizer.eos_token_id,  \n","        no_repeat_ngram_size=3,       \n","        do_sample=True, \n","        top_k=100, \n","        top_p=0.7,\n","        temperature=0.8\n","    )\n","    \n","    # pretty print last ouput tokens from bot\n","    print(\"Harry Potter bot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"]},{"cell_type":"markdown","metadata":{"id":"ANSQlQezXqwn"},"source":["## Push Model to Hugging Face"]},{"cell_type":"code","execution_count":260,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":650,"status":"ok","timestamp":1667577517466,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"HfRPhfaKxBcy","outputId":"7b163a62-3f59-49fd-dd2e-a6e0abeb02a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: -c: line 0: syntax error near unexpected token `'/content/''\n","/bin/bash: -c: line 0: `os.chdir('/content/')'\n"]}],"source":["!os.chdir('/content/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rn_C32UHxJWA"},"outputs":[],"source":["!pip install huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17850,"status":"ok","timestamp":1667574662142,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"Kejjsp4ixTgB","outputId":"f6de94d2-2f5c-4883-ee5c-ebda0735820f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n","        \n","Token: \n","Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xO1XRA13GGkL"},"outputs":[],"source":["git config --global credential.helper store"]},{"cell_type":"code","execution_count":261,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9733,"status":"ok","timestamp":1667577535233,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"OBMjXOPnFNqM","outputId":"179e2c0b-c5d3-4b07-a666-e96be1e0f337"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[90mgit version 2.17.1\u001b[0m\n","Error: unknown flag: --version\n","\n","\u001b[90mSorry, no usage text found for \"git-lfs\"\u001b[0m\n","\n","You are about to create \u001b[1msomesh212/Harry_Potter_botDialoGPT_Som\u001b[0m\n","Proceed? [Y/n] Y\n","\u003cclass 'requests.exceptions.HTTPError'\u003e (Request ID: kAxX60whL1wbnzoKEuC6Y)\n","\n","You already created this model repo - You already created this model repo\n","\u001b[1m\u001b[31m{\"error\":\"You already created this model repo\",\"url\":\"https://huggingface.co/somesh212/Harry_Potter_botDialoGPT_Som\"}\u001b[0m\n"]}],"source":["!huggingface-cli repo create Harry_Potter_botDialoGPT_Som"]},{"cell_type":"code","execution_count":262,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":717,"status":"ok","timestamp":1667577540867,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"QD7eYn6azNmw","outputId":"ccf32119-91ca-4f50-a807-5b5a8c248903"},"outputs":[{"name":"stdout","output_type":"stream","text":["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"]}],"source":["!cat /root/.huggingface/token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500,"status":"ok","timestamp":1667574695660,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"G0oV3XhH0Pyh","outputId":"8be889aa-6615-4b2a-d2c0-713e0cec5f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["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"]}],"source":["!cat /root/.huggingface/token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2067,"status":"ok","timestamp":1667574850213,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"jMpygKVfHDcG","outputId":"43858707-de53-4d1c-ef40-1014ba7958e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","git-lfs is already the newest version (2.3.4-1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"]}],"source":["!sudo apt-get install git-lfs"]},{"cell_type":"code","execution_count":263,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":634,"status":"ok","timestamp":1667577547117,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"vWKaeh12y9MO","outputId":"6c1b2d55-1221-4a2e-f154-0692048ee865"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Harry_Potter_botDialoGPT_Som' already exists and is not an empty directory.\n"]}],"source":["!git clone https://somesh212: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@huggingface.co/somesh212/Harry_Potter_botDialoGPT_Som"]},{"cell_type":"code","execution_count":265,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1667577563967,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"Y3MSt3-RXjN8","outputId":"3bc78ac1-50ab-4ba2-e9de-38b69a1aa41b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":266,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1667577582751,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"P-okd-tdXnSG","outputId":"1ce47c20-967d-4ed4-b400-3978e6f98b42"},"outputs":[{"name":"stdout","output_type":"stream","text":[" cached\t\t\t        kaggle\t\t  Untitled1.ipynb\n","'Copy of Untitled2.ipynb'       kaggle.json\t  Untitled2.ipynb\n"," dialogGPT_discord.ipynb        output-medium\t  Untitled3.ipynb\n"," Harry%20Potter%201.csv         output-small\t 'Untitled project.gscript'\n"," Harry_Potter_botDialoGPT_Som   runs\n"," harrypotterbot.ipynb\t        Untitled0.ipynb\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":267,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1667577614835,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"oIg8M8E5XrxW","outputId":"c1fd6337-0f7b-4d99-bac4-67ee3bd5f58a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/output-medium\n"]}],"source":["%cd output-medium"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgZCpeJLXzEz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":264,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1667577553017,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"5rVGvfHT4AxO","outputId":"90bf662c-2171-4946-a709-38e676272a34"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/output-medium/'\n","/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["%cd drive/MyDrive/Colab Notebooks/output-medium/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1667574725794,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"BTF9dmCW4H-9","outputId":"65222524-3ad9-4d48-d669-1d29cc3d8e4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":750,"status":"ok","timestamp":1667574721177,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"0tDIaWER4ME8","outputId":"50d6b2f2-e45d-48b5-c30e-09b43eab5682"},"outputs":[{"name":"stdout","output_type":"stream","text":["cached\t\t\t      harrypotterbot.ipynb  output-small\n","dialogGPT_discord.ipynb       kaggle\t\t    runs\n","Harry%20Potter%201.csv\t      kaggle.json\t    Untitled0.ipynb\n","Harry_Potter_botDialoGPT_Som  output-medium\t    Untitled1.ipynb\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":650,"status":"ok","timestamp":1667574896397,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"pKKfmsuG4V9x","outputId":"a0cf8127-3827-49e3-d8c0-d4cbfc4913a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1667574959248,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"cYXoJIL6NiIu","outputId":"49b7a70c-7d71-4f1d-bfa8-c8f9b9041920"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["%cd  Colab\\ Notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1667574963132,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"LEB1eesfJ5g7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any parent up to mount point /content)\\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\\n\"\n","Git LFS initialized.\n","Cloning into 'Harry_Potter_botDialoGPT_Som'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (3/3), done.\n"]}],"source":["!git lfs install\n","!git clone https://huggingface.co/somesh212/Harry_Potter_botDialoGPT_Som"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":950,"status":"ok","timestamp":1667574920198,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"mcOqL7IY1dgU","outputId":"a25eec62-41f1-47b2-9e2c-3cb2d8b1907b"},"outputs":[{"name":"stdout","output_type":"stream","text":["mv: cannot stat '/output-medium/*': No such file or directory\n"]}],"source":["!mv /output-medium/*  Harry_Potter_botDialoGPT_Som/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VgnHRgHKXwDd"},"outputs":[],"source":["!sudo apt-get install git-lfs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56Lk2s3eKFF1"},"outputs":[],"source":["os.chdir('Harry_Potter_botDialoGPT_Som')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":666,"status":"ok","timestamp":1667575108601,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"Env6G0qkNyI-","outputId":"73da8d97-7f29-48a6-f36a-032942d36742"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated git hooks.\n","Git LFS initialized.\n"]}],"source":["!git lfs install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1667575154252,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"yX6EvP2KKkNB","outputId":"61a1c7df-978a-4183-fb13-643573aa3971"},"outputs":[{"name":"stdout","output_type":"stream","text":["config.json\t  pytorch_model.bin\t   tokenizer.json\n","eval_results.txt  special_tokens_map.json  training_args.bin\n","merges.txt\t  tokenizer_config.json    vocab.json\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_fMioX7KUUE"},"outputs":[],"source":["%cd output-medium"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhqMtvfmXei8"},"outputs":[],"source":["!git config --global user.email \"someshgaur2606@gmail.com\"\n","# using the same email as your huggingface.co account will link your commits to your profile\n","!git config --global user.name \"someshgaur212\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fuw96p2HKpn5"},"outputs":[],"source":["!git lfs install"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1667575220854,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"2AQBG1mgKytK","outputId":"756503ac-2229-49f7-d7d2-7768469c11ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["On branch main\n","Your branch is ahead of 'origin/main' by 1 commit.\n","  (use \"git push\" to publish your local commits)\n","\n","nothing to commit, working tree clean\n"]}],"source":["!git status"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1667575617011,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"fmViDuPDK3y9","outputId":"59713697-6524-4bc0-e661-d56c04b34634"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Harry_Potter_botDialoGPT_Som\n"]}],"source":["!pwd\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQHJPwONK6_5"},"outputs":[],"source":["!git add ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjAFoOwoLOlU"},"outputs":[],"source":["!git config --global user.email \"someshgaur2606@gmail.com\"\n","# using the same email as your huggingface.co account will link your commits to your profile\n","!git config --global user.name \"somesh212\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500,"status":"ok","timestamp":1667575605978,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"RiFXNZFy5tft","outputId":"28925fce-a9b9-4ccd-ca5b-dbd9599ac466"},"outputs":[{"name":"stdout","output_type":"stream","text":["On branch main\n","Your branch is ahead of 'origin/main' by 1 commit.\n","  (use \"git push\" to publish your local commits)\n","\n","nothing to commit, working tree clean\n"]}],"source":["!git commit -m \"second commit\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1450,"status":"ok","timestamp":1667575253638,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"dF31oqpK6Vem","outputId":"056fb2fd-3da3-4d32-e476-df135703295a"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: could not read Username for 'https://huggingface.co': No such device or address\n"]}],"source":["!git push"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"elapsed":567,"status":"error","timestamp":1667575517376,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"tfUsrKR7YLT1","outputId":"48ea6adf-9326-490d-a43a-b9464977fe64"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-240-7690e67c8520\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMY_MODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Harry_Potter_bot'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HuggingFace-API-key.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mHUGGINGFACE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HuggingFace-API-key.txt'"]}],"source":["MY_MODEL_NAME = 'Harry_Potter_bot'\n","with open('HuggingFace-API-key.txt', 'rt') as f:\n","  HUGGINGFACE_API_KEY = f.read().strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_65nsiLcYNXI"},"outputs":[],"source":["model.push_to_hub(MY_MODEL_NAME, use_auth_token=HUGGINGFACE_API_KEY)\n","tokenizer.push_to_hub(MY_MODEL_NAME, use_auth_token=HUGGINGFACE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"D_XfXTCrZKmO"},"source":["## All Done!"]},{"cell_type":"code","execution_count":245,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":567,"status":"ok","timestamp":1667576321909,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"_tIwK7G8ZLrd","outputId":"6ed926c0-df6c-42fb-dbc5-e7ffab756ac4"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Harry_Potter_botDialoGPT_Som\n"]}],"source":["!pwd\n"]},{"cell_type":"code","execution_count":246,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633,"status":"ok","timestamp":1667576350209,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"Wg8AlbveSy8o","outputId":"cad2a19f-2871-4780-a2b2-06aa47954cef"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":247,"metadata":{"executionInfo":{"elapsed":984,"status":"ok","timestamp":1667576375977,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"ojBPokc1S9FW"},"outputs":[],"source":["os.chdir('/content/')"]},{"cell_type":"code","execution_count":248,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4733,"status":"ok","timestamp":1667576403477,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"aeBcyCi8TENF","outputId":"3cc5d4be-ab98-4fd5-8847-e64da5cd79ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.7/dist-packages (0.10.1)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (2.23.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.1.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.13.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (3.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface_hub) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.9-\u003ehuggingface_hub) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003ehuggingface_hub) (3.10.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ehuggingface_hub) (2022.9.24)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ehuggingface_hub) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ehuggingface_hub) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003ehuggingface_hub) (2.10)\n"]}],"source":["!pip install huggingface_hub"]},{"cell_type":"code","execution_count":249,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262122,"status":"ok","timestamp":1667576756768,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"EMQ__aJhTbdZ","outputId":"ab8882c5-0162-482e-aab0-1f69bb158c92"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n","        \n","Token: \n","Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":250,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2267,"status":"ok","timestamp":1667576840236,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"pq4FzpkfTNyo","outputId":"81165b60-46a3-4c43-c726-9fd5b6fb54ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","git-lfs is already the newest version (2.3.4-1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"]}],"source":["!sudo apt-get install git-lfs"]},{"cell_type":"code","execution_count":251,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1667576991706,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"ebEVUNejU5Ck"},"outputs":[],"source":["!git config --global user.email \"someshgaur2606@gmail.com\"\n","# Tip: using the same email as your huggingface.co account will link your commits to your profile\n","!git config --global user.name \"somesh212\""]},{"cell_type":"code","execution_count":255,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2533,"status":"ok","timestamp":1667577187426,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"z7hBkBn0Vy4N","outputId":"7cd36d97-0cd7-44f6-d580-46c8331172ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'Harry_Potter_botDialoGPT_Som' already exists and is not an empty directory.\n"]}],"source":["\n","!git clone https://huggingface.co/somesh212/Harry_Potter_botDialoGPT_Som"]},{"cell_type":"code","execution_count":256,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550,"status":"ok","timestamp":1667577333329,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"5KqIoSIeWKNu","outputId":"e4d1930e-b2a5-4dd4-86f8-1facf41ac8f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["!pwd\n"]},{"cell_type":"code","execution_count":259,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":533,"status":"ok","timestamp":1667577503799,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"f8v4NuIKWu4p","outputId":"573fb3a0-6b03-405c-9f18-fef799e0f548"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["%cd drive/MyDrive/Colab Notebooks"]},{"cell_type":"code","execution_count":252,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"elapsed":567,"status":"error","timestamp":1667577063774,"user":{"displayName":"Somesh Gaur","userId":"10381250260654664519"},"user_tz":0},"id":"cjs0qrHhVdAt","outputId":"0bbaf569-ba88-419a-cb9a-1444e0e67ee6"},"outputs":[{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-252-798cfe107893\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMY_MODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DialoGPT-small-HarryPotter'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HuggingFace-API-key.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mHUGGINGFACE_API_KEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'HuggingFace-API-key.txt'"]}],"source":["model.push_to_hub(MY_MODEL_NAME, use_auth_token=HUGGINGFACE_API_KEY)\n","tokenizer.push_to_hub(MY_MODEL_NAME, use_auth_token=HUGGINGFACE_API_KEY)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"","provenance":[{"file_id":"https://github.com/RuolinZheng08/twewy-discord-chatbot/blob/main/model_train_upload_workflow.ipynb","timestamp":1667565611061}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":0}